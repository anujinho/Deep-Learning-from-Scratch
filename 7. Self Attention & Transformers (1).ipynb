{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssLI7a7GKzgB"
   },
   "source": [
    "# CS4240 Deep Learning - Assignment 7\n",
    "\n",
    "*These lab assignments are new in the CS4240 Deep Learning course. We'd like to hear what you think!*\n",
    "\n",
    "*Please post any feedback you have on [Brightspace](https://brightspace.tudelft.nl/d2l/le/280420/discussions/topics/48829/View). Thanks!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OL148V_8rxq5"
   },
   "source": [
    "To start working on the assignment in Colab, save a copy on your Google Drive (`File` $\\rightarrow$ `Save a copy in Drive`).\n",
    "\n",
    "To work on the assignments locally, configure your conda environment (see instructions on Brightspace) and download this assignment as an IPython Notebook (`File` $\\rightarrow$ `Download .ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdx7o5N2S2Tn"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment you will learn about self-attention and transformers and implement them as PyTorch layers. Finally, you will train a transformer architecture on MNIST-1D. We have heavily borrowed from [this excellent blog post on Transformers](http://peterbloem.nl/blog/transformers) and as such most answers to the questions can be found there. We encourage you to read it, but also to think about the implementations yourself before looking up the solutions.\n",
    "\n",
    "**Prerequisites:**\n",
    "* Completion of previous assignments (1-6).\n",
    "* Basic knowledge of Python and Numpy. </br> Recommended tutorial for Python and Numpy [here](https://cs231n.github.io/python-numpy-tutorial/).\n",
    "* We recommend you to have a look at [this excellent tutorial on PyTorch Tensors](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py).\n",
    "\n",
    "**Learning objectives:**\n",
    "* Understanding, implementing and using self-attention layers and transformer blocks.\n",
    "\n",
    "---\n",
    "\n",
    "When answering coding questions make sure to write your own code within the designated part of the code block as illustrated here:\n",
    "```python \n",
    "#############################################################################\n",
    "#                       TODO: Implement function x                          #\n",
    "#############################################################################\n",
    "# Replace \"pass\" statement with your code\n",
    "pass\n",
    "#############################################################################\n",
    "#                            END OF YOUR CODE                               #\n",
    "#############################################################################\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTywYGOy4-Rw"
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Additional Setup to use Tensorboard\n",
    "!pip install -q tensorflow\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Additional Setup for IMDB sentiment analysis dataset\n",
    "from torchtext import data, datasets, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rc7tVWiv3HEk"
   },
   "source": [
    "## A7.1 Basic Self-Attention\n",
    "\n",
    "Self-attention forms the basis of the transformer architectures, a relatively novel family of machine learning models designed for sequential data but recently also gaining traction for vision applications.\n",
    "\n",
    "Given an sequence of input vectors $\\mathbf{x_1},\\mathbf{x_2},...,\\mathbf{x_t}$ the output of the self-attention operation is defined as a weighted sum of these vectors\n",
    "$$\\mathbf{y_i} = \\sum_j w_{ij}\\mathbf{x_j},$$\n",
    "with the weights are defined as \n",
    "$$w_{ij}  = \\frac{\\exp w_{ij}'}{\\sum_j \\exp w_{ij}'}, \\qquad w_{ij}' = \\mathbf{x_i}^T\\mathbf{x_j}.$$\n",
    "\n",
    "This may seem like a fairly arbitrary operation. For now it's sufficient to understand that the dot product $\\mathbf{x_i}^T\\mathbf{x_j}$ measures the similarity between two input vectors, which is then normalized between $[0,1]$ by the softmax operation. The output $\\mathbf{y_i}$ is a weighted sum over all input vectors $\\mathbf{x}$, with the weights determined by the similarity between $\\mathbf{x_i}$ and the other input vectors $\\mathbf{x}$. We hope to build up some more intuition later on.\n",
    "\n",
    "You will now implement the basic self-attention operation as a PyTorch layer. As the operation so far has no learnable parameters, we can omit the `__init__` method and only need to define `forward`. Assume that the input tensor `x` has shape `[b, t, k]`, which represent the batch size, sequence length and embedding dimension, i.e. the dimensionality of the input vector, respectively.\n",
    "\n",
    "*Hint: use `torch.bmm` for computing $w'$ and $\\mathbf{y}$. This performs a batched matrix multiplication. See the [[docs](https://pytorch.org/docs/stable/generated/torch.bmm.html)] for more information.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiPDXjoE6CZA"
   },
   "outputs": [],
   "source": [
    "class BasicSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic self-attention operation.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        ########################################################################\n",
    "        #      TODO: Perform the basic self-attention operation. Calculate     #\n",
    "        #        w_prime, apply softmax and compute the output tensor y.       #\n",
    "        ########################################################################\n",
    "        \n",
    "        \n",
    "\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qn92W0XO6qO7"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "b, t, k = 4, 5, 6\n",
    "x = torch.randn((b, t, k))\n",
    "\n",
    "y_expected = torch.tensor([[[ 0.2834, -0.4717,  0.3321, -0.6988, -0.0261,  0.1891],\n",
    "         [-0.1848, -0.3588,  0.7735, -1.1254,  0.6304, -1.3145],\n",
    "         [ 0.1355,  1.7529,  0.6207,  0.3672,  0.0860, -0.9289],\n",
    "         [-0.1611,  0.9364,  1.5545,  1.2723,  1.2436, -0.2212],\n",
    "         [ 0.4915, -1.5603,  0.9615, -1.1464, -1.1427,  0.3158]],\n",
    "\n",
    "        [[-0.6315, -2.8400, -1.3250,  0.1784, -2.1337,  1.0524],\n",
    "         [-0.3983, -1.0677, -0.5495, -0.9887,  0.6507,  1.5104],\n",
    "         [ 0.5973, -0.1904,  0.4956, -0.3068, -0.0800,  0.2620],\n",
    "         [ 0.8767,  1.6216, -1.4779,  1.1329, -1.2203,  1.3138],\n",
    "         [ 1.0519,  0.1379,  2.2433, -0.8030, -0.2798,  0.7691]],\n",
    "\n",
    "        [[-0.1880, -1.0476,  0.1575,  0.1553,  0.2362,  0.9297],\n",
    "         [-0.2588, -1.0825, -0.0444,  1.6233, -2.3225,  1.0878],\n",
    "         [ 0.3692,  0.4108, -0.6754, -0.2787, -0.4787,  0.0212],\n",
    "         [ 0.3307, -1.3707,  0.2412, -0.4630,  0.9333,  0.8396],\n",
    "         [-0.3934,  0.4887, -0.2176, -1.7437, -1.6007, -1.0739]],\n",
    "\n",
    "        [[ 1.2047, -0.7042, -0.5500, -0.5239,  0.6471, -1.0410],\n",
    "         [-2.2339, -1.2494, -2.0563,  0.9558, -0.0572, -0.4956],\n",
    "         [ 0.7503, -0.0558, -0.6242,  1.0989, -0.9712, -0.4562],\n",
    "         [-2.6620,  0.3284, -1.2617,  0.7977, -0.6292, -0.8713],\n",
    "         [ 3.8954, -0.6027, -0.0480,  0.5349,  1.1031,  1.3334]]])\n",
    "\n",
    "module = BasicSelfAttention()\n",
    "y = module(x)\n",
    "\n",
    "print('Output shape:', y.shape)\n",
    "print('Output is correct:', torch.allclose(y, y_expected, atol=1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsGtVLzUfYJ7"
   },
   "source": [
    "## A7.2 Queries, keys and values\n",
    "\n",
    "So far, our self-attention operation did not contain any trainable parameters. So where exactly does the learning happen, and what does self-attention even do?\n",
    "\n",
    "In reality, the input vectors $\\mathbf{x}$ serve three different purposes in the self-attention operation, namely as the *query*, *key* and *value*. The input vectors $\\mathbf{x}$ are transformed to new vectors for each of these purposes using learnable weights $\\mathbf{W}$:\n",
    "\n",
    "$$\\mathbf{q_i} = \\mathbf{W_q} \\mathbf{x_i} \\qquad \\mathbf{k_i} = \\mathbf{W_k} \\mathbf{x_i} \\qquad \\mathbf{v_i} = \\mathbf{W_v} \\mathbf{x_i}.$$\n",
    "\n",
    "The same weights are thus used for each input vector in the sequence and different weights are used for the query, key and value mappings, respectively. The weight matrices have size $k \\times k$ such that the dimensionality of the query, key and value vectors, and thus also the output vectors, will be equal to the embedding dimension. The basic self-attention operation now becomes\n",
    "\n",
    "$$w_{ij} = \\text{softmax}(w_{ij}'), \\qquad w_{ij}' = \\frac{\\mathbf{q_i}^T \\mathbf{k_j}}{\\sqrt{k}}, \\qquad \\mathbf{y_i} = \\sum_j w_{ij}\\mathbf{v_j}.$$\n",
    "\n",
    "Note the scaling of $w_{ij}'$ by $\\frac{1}{\\sqrt{k}}$, where $k$ is the embedding dimension. This scaling is needed to prevent $w_{ij}'$ from becoming very large, which would kill the gradient in the softmax operation.\n",
    "\n",
    "So what exactly is happening here? The query, key and value encodings allow self-attention to learn relationships between the input vectors. More specifically, the query encoding $\\mathbf{q_i}$ asks a question to all input vectors $\\mathbf{x_j}$, e.g. for an NLP task it may ask \"Are you a noun?\". The key encoding $\\mathbf{k_j}$ can then represent the \"noun-ness\" of an input vector $\\mathbf{x_j}$, such that the dot product between the query $\\mathbf{q_i}$ and the key $\\mathbf{k_j}$ will return a high number if the input vector $\\mathbf{x_j}$ is indeed a noun and a low number if it is not. The value encoding $\\mathbf{v_j}$ denotes the information that needs to be passed on from the input vector $\\mathbf{x_j}$: if the input vector $\\mathbf{x_j}$ is a noun, the query-key dot product $\\mathbf{q_i}^T \\mathbf{k_j}$ will yield a high weight and the output $\\mathbf{y_i}$ will for a large part consist of the input vector's value $\\mathbf{v_j}$.\n",
    "\n",
    "You will now implement the basic self-attention layer in PyTorch. The linear transformations by learnable weights $\\mathbf{W}$ can be implemented as linear layers without a bias. We have predefined this in the `__init__` method - your task is to implement the `forward` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9PHr4MdBTar"
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Self-attention operation with learnable key, query and value embeddings.\n",
    "    \n",
    "    Args:\n",
    "        k: embedding dimension\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, k):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        # These compute the queries, keys and values\n",
    "        self.tokeys    = nn.Linear(k, k, bias=False)\n",
    "        self.toqueries = nn.Linear(k, k, bias=False)\n",
    "        self.tovalues  = nn.Linear(k, k, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Get tensor dimensions: batch size, sequence length and embedding dimension\n",
    "        b, t, k = x.size()\n",
    "\n",
    "        ########################################################################\n",
    "        #   TODO: Perform self-attention operation with learnable query, key   #\n",
    "        #         and value mappings. Calculate w_prime, apply scaling,        #\n",
    "        #               softmax and compute the output tensor y.               #\n",
    "        ########################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhEDP3Xt67X_"
   },
   "source": [
    "Now test your implementation - `y_expected` should be the output tensor given the random input `x` generated with the predefined seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dE0valvADqv6"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "b, t, k = 4, 5, 6\n",
    "\n",
    "x = torch.randn((b, t, k))\n",
    "\n",
    "y_expected = torch.tensor([[[ 0.1231,  0.1778,  0.2974,  0.0500,  0.1120,  0.1038],\n",
    "         [ 0.0325,  0.2101,  0.2200,  0.0707,  0.0866,  0.0673],\n",
    "         [ 0.0048,  0.2510,  0.2972,  0.1344,  0.0983,  0.0718],\n",
    "         [-0.0014,  0.2166,  0.1966,  0.0775,  0.0772,  0.0434],\n",
    "         [ 0.2281,  0.0722,  0.1451, -0.1040,  0.0864,  0.1377]],\n",
    "\n",
    "        [[-0.2472, -0.1619, -1.0090, -0.3549, -0.3676, -0.0785],\n",
    "         [-0.4032,  0.1552, -0.2922,  0.1084, -0.1575, -0.1039],\n",
    "         [-0.3656,  0.0877, -0.4949, -0.0231, -0.2014, -0.0868],\n",
    "         [-0.3423,  0.2578, -0.2545,  0.0664, -0.1521, -0.0647],\n",
    "         [-0.2659,  0.0660, -0.6030, -0.1627, -0.2108, -0.0870]],\n",
    "\n",
    "        [[-0.3335,  0.0177, -0.1816,  0.1639, -0.1403,  0.0153],\n",
    "         [-0.2958, -0.0396, -0.3106,  0.0819, -0.1974,  0.0308],\n",
    "         [-0.2239,  0.0679, -0.0889,  0.1412, -0.0252,  0.0831],\n",
    "         [-0.2898,  0.0234, -0.1717,  0.1343, -0.1102,  0.0119],\n",
    "         [-0.2114,  0.0575, -0.1183,  0.1180, -0.0374,  0.0794]],\n",
    "\n",
    "        [[ 0.0918, -0.2833,  0.0635,  0.0059, -0.2173, -0.2903],\n",
    "         [ 0.1424, -0.4694,  0.3173,  0.1795, -0.0194, -0.0314],\n",
    "         [ 0.0183, -0.2170, -0.1183, -0.0777, -0.3578, -0.4527],\n",
    "         [ 0.1239, -0.4252,  0.3004,  0.1618, -0.0555, -0.1295],\n",
    "         [ 0.0168, -0.1536, -0.1627, -0.1242, -0.3946, -0.5308]]])\n",
    "\n",
    "module = SelfAttention(k)\n",
    "y = module(x)\n",
    "\n",
    "print('Output shape:', y.shape)\n",
    "print('Output is correct:', torch.allclose(y, y_expected, atol=1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV-DWJtzfgLj"
   },
   "source": [
    "## A7.3 Multi-head attention\n",
    "\n",
    "We can increase the discriminative power of self-attention by defining multiple linear transformations $\\mathbf{W}$ for the queries, keys and values. This allows the self-attention layer to learn multiple *different* relationships between different input vectors. These different transformations are called *attention heads* and we'll index them by $r$, such that we will have weights $\\mathbf{W_q^r}$, $\\mathbf{W_k^r}$ and $\\mathbf{W_v^r}$. For each input vector $\\mathbf{x_i}$ we will then get multiple query, key and value vectors $\\mathbf{q_i^r}$, $\\mathbf{k_i^r}$ and $\\mathbf{v_i^kr}$, and multiple output vectors $\\mathbf{y_i^r}$. These output vectors are concatenated and mapped back to the original embedding dimension $k$ using a learnable linear transformation, if needed.\n",
    "\n",
    "Two different versions of multi-head self-attension exist:\n",
    "* In **narrow** multi-head self-attention the input vector is mapped to a lower-dimensional feature vector. E.g. an embedding dimension of 256 with 8 attention heads would map the entire 256-dimensional input vector $\\mathbf{x_i}$ to 8 different 32-dimensional query, key and value vectors, resulting in 8 32-dimensional output vectors $\\mathbf{y^r}$. These are then concatenated back to the original embedding dimension of 256.\n",
    "* In **wide** multi-head self-attention each attention head maps the input vectors to representations of the same dimensionality. An embedding dimension of 256 with 8 attention heads would thus result in 8 256-dimensional output vectors $\\mathbf{y^r}$. These are then concatenated to and mapped back to the original dimension of 256 using a learnable linear transformation.\n",
    "\n",
    "Narrow multi-head self-attention is more computationally efficient, but has somewhat less expressive power compared to wide multi-head self-attention.\n",
    "\n",
    "You will now implement the wide multi-head self-attention layer. Again, we have already written the `__init__` method - your task is to implement the `forward` method. Note that the `tokeys`, `toqueries` and `tovalues` Linear layers map to a `k * heads` dimensional representation. These can be reshaped to tensors of shape `(b, t, h, k)`. The key is then to fold the heads dimension (`h`) into the batch dimension (`b`) using the `.transpose` (or `.permute`) and the `.reshape` operation such that we get tensors of shape `(b * h, t, k)`, perform batched matrix multiplication on these tensors, and unfold them back to their original shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsGh2_FCEBy2"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Wide mult-head self-attention layer.\n",
    "\n",
    "    Args:\n",
    "        k: embedding dimension\n",
    "        heads: number of heads (k mod heads must be 0)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, k, heads=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.heads = heads\n",
    "\n",
    "        # These compute the queries, keys and values for all \n",
    "        # heads (as a single concatenated vector)\n",
    "        self.tokeys    = nn.Linear(k, k * heads, bias=False)\n",
    "        self.toqueries = nn.Linear(k, k * heads, bias=False)\n",
    "        self.tovalues  = nn.Linear(k, k * heads, bias=False)\n",
    "\n",
    "        # This unifies the outputs of the different heads into \n",
    "        # a single k-vector\n",
    "        self.unifyheads = nn.Linear(k * heads, k)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        b, t, k = x.size()\n",
    "        h = self.heads\n",
    "\n",
    "        ########################################################################\n",
    "        #     TODO: Perform wide multi-head self-attention operation with      #\n",
    "        #   learnable query, key and value mappings. Calculate w_prime, apply  #\n",
    "        #  scaling, softmax and compute and concatenate the output tensors y,  #\n",
    "        #        and transform back to the original embedding dimension.       #\n",
    "        ########################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-vWyOJQAEES"
   },
   "source": [
    "Now again test your implementation - `y_expected` should be the output tensor given the random input `x` generated with the predefined seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahyBDoGCO1PP"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "b, t, k = 4, 5, 6\n",
    "\n",
    "x = torch.randn((b, t, k))\n",
    "\n",
    "y_expected = torch.tensor([[[ 0.0035,  0.3010, -0.0621,  0.4070, -0.2123, -0.1487],\n",
    "         [ 0.0243,  0.3058, -0.0935,  0.4081, -0.1942, -0.0343],\n",
    "         [ 0.0962,  0.2899, -0.1183,  0.4153, -0.1463, -0.1108],\n",
    "         [ 0.1387,  0.2505, -0.1208,  0.4117, -0.1090, -0.1930],\n",
    "         [ 0.0224,  0.2921, -0.0991,  0.3883, -0.2183, -0.1133]],\n",
    "\n",
    "        [[ 0.0770, -0.0225, -0.3547,  0.1424,  0.1842, -0.3233],\n",
    "         [-0.0676, -0.0540, -0.2001,  0.1620,  0.0864, -0.3736],\n",
    "         [ 0.1304, -0.1026, -0.3544,  0.0990,  0.2506, -0.2185],\n",
    "         [ 0.0915, -0.1286, -0.3127,  0.0048,  0.2420, -0.4214],\n",
    "         [ 0.0874, -0.1273, -0.3167, -0.0123,  0.2531, -0.3746]],\n",
    "\n",
    "        [[ 0.0184, -0.0246, -0.1923,  0.1095,  0.0736, -0.3111],\n",
    "         [ 0.0628,  0.0008, -0.2398,  0.1433,  0.0947, -0.2898],\n",
    "         [ 0.0537,  0.0056, -0.2244,  0.1059,  0.0896, -0.3198],\n",
    "         [-0.0046, -0.0337, -0.1608,  0.1234,  0.0521, -0.3232],\n",
    "         [ 0.0099,  0.1433, -0.2173,  0.1083,  0.0402, -0.2639]],\n",
    "\n",
    "        [[ 0.5510, -0.0170, -0.4702, -0.0702,  0.3278,  0.1206],\n",
    "         [ 0.4921,  0.0563, -0.5699, -0.1913,  0.4210,  0.0652],\n",
    "         [ 0.5200,  0.0529, -0.4604, -0.1243,  0.2670,  0.0184],\n",
    "         [ 0.4255,  0.0415, -0.5621, -0.2178,  0.4525,  0.0554],\n",
    "         [ 0.6228, -0.0517, -0.4704, -0.0123,  0.2892,  0.0539]]])\n",
    "\n",
    "module = MultiHeadAttention(k, heads=3)\n",
    "y = module(x)\n",
    "\n",
    "print('Output shape:', y.shape)\n",
    "print('Output is correct:', torch.allclose(y, y_expected, atol=1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhoHWyzIh1Eq"
   },
   "source": [
    "## A7.4 Transformers\n",
    "\n",
    "We will now construct the transformer block, which forms the basic building block of a transformer architecture. Although different implementations exist, we will consider a fairly simple and generic version depicted in the image below:\n",
    "\n",
    "![transformer.PNG](data:image/png;base64,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)\n",
    "\n",
    "[image credits: [http://peterbloem.nl/blog/transformers](http://peterbloem.nl/blog/transformers)]\n",
    "\n",
    "The transformer block thus consists of a self-attention layer, followed by layer norm, a MLP applied on each vector individually and another layer norm. Note the residual connections in the self-attention and MLP layer.\n",
    "\n",
    "Now implement the transformer block as a PyTorch layer. All different components are already defined in `__init__` - your task is to connect them in the proper way in the `forward` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHoql_aU1kEf"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, k, heads, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Basic transformer block.\n",
    "\n",
    "        Args:\n",
    "            k: embedding dimension\n",
    "            heads: number of heads (k mod heads must be 0)\n",
    "\n",
    "        \"\"\"\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.att = MultiHeadAttention(k, heads=heads)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(k)\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(k, 4 * k),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * k, k))\n",
    "        \n",
    "        self.norm2 = nn.LayerNorm(k)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of trasformer block.\n",
    "\n",
    "        Args:\n",
    "            x: input with shape of (b, k)\n",
    "        \n",
    "        Returns:\n",
    "            y: output with shape of (b, k)\n",
    "        \"\"\"\n",
    "        ########################################################################\n",
    "        #        TODO: Perform the forward pass of a transformer block         #\n",
    "        #                       as depicted in the image.                      #\n",
    "        ########################################################################\n",
    "\n",
    "\n",
    "\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_IfFWU30scc"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "b, t, k = 4, 5, 6\n",
    "\n",
    "x = torch.randn((b, t, k))\n",
    "\n",
    "y_expected = torch.tensor([[[ 0.7410, -0.0098, -1.6372, -0.7155,  0.1238,  1.4976],\n",
    "         [ 0.3302,  0.1532,  1.3658, -0.8297,  0.6722, -1.6917],\n",
    "         [ 0.2061,  1.7712,  0.2474,  0.0786, -0.9281, -1.3753],\n",
    "         [-0.7928,  0.3866,  1.0414,  1.0690,  0.0261, -1.7303],\n",
    "         [ 1.0526, -1.4424,  1.2796, -0.3720, -0.9303,  0.4126]],\n",
    "\n",
    "        [[ 0.1214, -1.6620, -0.8036,  1.2432,  0.0892,  1.0117],\n",
    "         [-0.3496, -1.0407, -0.7206, -0.6595,  1.3490,  1.4214],\n",
    "         [ 1.6434, -0.4602, -0.4305, -0.1173,  0.8413, -1.4767],\n",
    "         [ 0.5016,  1.1910, -1.7864,  0.5852, -0.8269,  0.3355],\n",
    "         [ 0.9192, -0.5294,  1.6293, -1.4026, -0.4855, -0.1310]],\n",
    "\n",
    "        [[-1.0692, -1.4507, -0.2482,  0.6545,  1.1771,  0.9364],\n",
    "         [-0.3693, -0.9339, -0.1780,  1.9624, -0.9452,  0.4639],\n",
    "         [ 1.1320,  1.2037, -1.7683, -0.1069, -0.1177, -0.3428],\n",
    "         [ 0.4731, -1.8217, -0.0605, -0.4119,  1.4701,  0.3509],\n",
    "         [ 0.5669,  1.6360,  0.4623, -1.0489, -1.2450, -0.3713]],\n",
    "\n",
    "        [[ 1.7579, -0.4814, -0.7436, -0.6281,  0.9766, -0.8814],\n",
    "         [-0.8000, -0.4278, -1.4413,  1.4204,  1.0131,  0.2356],\n",
    "         [ 1.3927,  0.3766, -1.3574,  1.0216, -0.6657, -0.7678],\n",
    "         [-1.4835,  1.2110, -0.7496,  1.2892,  0.0578, -0.3248],\n",
    "         [ 1.8534, -1.0981, -1.0474, -0.2566,  0.4255,  0.1232]]])\n",
    "\n",
    "module = TransformerBlock(k, heads=3, dropout=0)\n",
    "y = module(x)\n",
    "\n",
    "print('Output shape:', y.shape)\n",
    "print('Output is correct:', torch.allclose(y, y_expected, atol=1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLk41aDMi7mL"
   },
   "source": [
    "## A7.5 Position embeddings and the Transformer architecture\n",
    "\n",
    "Self-attention is permutation equivariant: changing the order of the input sequence will result in the exact same output sequence, but also with the same changes in the order. This equivariance property is not always desirable. Imagine we want to use a transformer architecture for sequence classification. To represent the whole sequence by a single feature vector we can append a pooling layer before the final classification layer. However, this would make the transformer architecture permutation invariant, i.e. it would give the same prediction regardless of the order of the sequence.\n",
    "\n",
    "We can choose to explicitly include position information by adding values that encode position to the input vectors. A simple way to do this is by using the `nn.Embedding` module in PyTorch to learn position embeddings - see the [[docs](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)] for more information. These are then simply summed to the input sequence.\n",
    "\n",
    "The code for the transformer architecture is given below - you don't need to implement anything. Do examine the `forward` method though, especially the parts concerning the position embedding and average pooling. What does `self.output_projector` do and why is this necesary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVQvhAQwZOJH"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, k, heads=8, num_layers=2, input_length=40,\n",
    "                 num_inputs=256, num_outputs=10, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Transformer architecture.\n",
    "\n",
    "        Args:\n",
    "            k: embedding dimension\n",
    "            heads: number of attention heads\n",
    "            num_layers: number of transformer blocks in network\n",
    "            input_length: length of input sequence\n",
    "            num_inputs: input dimension\n",
    "            num_outputs: ouput dimension\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # Embedding layers for input and position\n",
    "        self.input_embedding = nn.Embedding(num_inputs, k)\n",
    "        self.position_embedding = nn.Embedding(input_length, k)\n",
    "\n",
    "        # Create transformer blocks\n",
    "        blocks = [TransformerBlock(k, heads, dropout=dropout) for _ in range(num_layers)]\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "\t\t# Projects the output to desired output size\n",
    "        self.output_projector = nn.Linear(k, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of trasformer model.\n",
    "\n",
    "        Args:\n",
    "            x: input with shape of (b, t)\n",
    "        \"\"\"\n",
    "        b, t = x.shape\n",
    "\n",
    "        # Embed input\n",
    "        x = self.input_embedding(x)\n",
    "\n",
    "\t\t# Add positional embedding\n",
    "        p = torch.arange(t, device=x.device).view(1, t).expand(b, t)\n",
    "        p = self.position_embedding(p)\n",
    "        x = x + p\n",
    "\n",
    "        # Compute transformer output\n",
    "        x = self.blocks(x)\n",
    "        \n",
    "        # Average-pool over dimension t\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        # Project output to desired size\n",
    "        x = self.output_projector(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg4y7uDh2Ez0"
   },
   "source": [
    "## A7.6 Train on IMDB dataset\n",
    "\n",
    "You are ready to use your Trasformer model to perform sentiment classification on text data! For this we will use the IMDB dataset of movie reviews, where for each entry we will predict how positive or negative they score.\n",
    "\n",
    "The following code block loads and structures the data. Contrary to the previous assignments our inputs now consist of integers instead of floats because we are now working with embeddings. Let's first prepare and examine the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3O_Vco2kung"
   },
   "outputs": [],
   "source": [
    "# Dataset related params\n",
    "NUM_CLASSES = 2\n",
    "VOCAB_SIZE = 50_000\n",
    "MAX_LENGTH = 512\n",
    "GRADIENT_CLIPPING = 1.0\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Set up fields\n",
    "TEXT = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
    "LABEL = data.Field(sequential=False)\n",
    "\n",
    "# Make splits for data\n",
    "train_data, _ = datasets.IMDB.splits(TEXT, LABEL)\n",
    "train_data, test_data = train_data.split(split_ratio=0.8)\n",
    "\n",
    "# Build the vocabulary, -2 is to make space for <unk> and <pad>\n",
    "TEXT.build_vocab(train_data, max_size=VOCAB_SIZE - 2)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "# Make iterator for splits\n",
    "train_iter, test_iter = data.BucketIterator.splits((train_data, test_data),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    device=DEVICE)\n",
    "\n",
    "# Print some example data\n",
    "for i in range(5):\n",
    "    print('Text: \\t', ' '.join(train_data[i].text))\n",
    "    print('Label: \\t', train_data[i].label)\n",
    "\n",
    "\n",
    "print(f'# of training examples: {len(train_data)}')\n",
    "print(f'# of test examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESi5KjQjgnN8"
   },
   "source": [
    "In similar fashion as in the previous assignment, we create some *utility* functions that make life easy when defining a main code block to run from. The following utility functions are created:\n",
    "\n",
    "1. `train`: trains and updates the model. Needs a training data set, specific model, optimizer and loss function as inputs. This training procedure updates for 1 epoch only (see `run` later on).\n",
    "2. `test`: tests a model on a specific data set (can be train, validation and/or testset). Needs the loader, model and loss function as inputs.\n",
    "3. `run`: To make playing with transformer model different hyperparameters more straightforward, we provide the `run` function which you can give hyperparameters as arguments. The training procedure is consistent with previous assignments and makes use of `train` and `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSKahJCmHmYp"
   },
   "outputs": [],
   "source": [
    "def train(train_iter, model, optimizer, lr_scheduler, criterion):\n",
    "    \"\"\"\n",
    "    Trains network for one epoch in batches.\n",
    "\n",
    "    Args:\n",
    "        train_iter: Data iterator for training set.\n",
    "        model: Neural network model.\n",
    "        optimizer: Optimizer (e.g. SGD).\n",
    "        lr_scheduler: Scheduler for adjusting the optimization learning rate.\n",
    "        criterion: Loss function (e.g. cross-entropy loss).\n",
    "    \"\"\"\n",
    "  \n",
    "    avg_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    # Iterate through batches\n",
    "    for batch in tqdm(train_iter):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input = batch.text[0]\n",
    "        label = batch.label - 1\n",
    "\n",
    "        if input.size(1) > MAX_LENGTH:\n",
    "            input = input[:, :MAX_LENGTH]\n",
    "        output = model(input)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients if the total gradient vector has a length > 1, we\n",
    "        # clip it back down to 1.\n",
    "        if GRADIENT_CLIPPING > 0.0:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIPPING)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Keep track of loss and accuracy\n",
    "        avg_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "\n",
    "    return avg_loss / len(train_iter), 100 * correct / total\n",
    "\n",
    "\n",
    "def test(test_iter, model, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates network in batches.\n",
    "\n",
    "    Args:\n",
    "        test_iter: Data iterator for test set.\n",
    "        model: Neural network model.\n",
    "        criterion: Loss function (e.g. cross-entropy loss).\n",
    "    \"\"\"\n",
    "\n",
    "    avg_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Use torch.no_grad to skip gradient calculation, not needed for evaluation\n",
    "    with torch.no_grad():\n",
    "        # Iterate through batches\n",
    "        for batch in tqdm(test_iter):\n",
    "\n",
    "            input = batch.text[0]\n",
    "            label = batch.label - 1\n",
    "\n",
    "            if input.size(1) > MAX_LENGTH:\n",
    "                input = input[:, :MAX_LENGTH]\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(input)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            # Keep track of loss and accuracy\n",
    "            avg_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "    return avg_loss / len(test_iter), 100 * correct / total\n",
    "\n",
    "\n",
    "def run(epochs=80, k=128, heads=6, num_layers=6, dropout=0.1):\n",
    "    \"\"\"\n",
    "    Run a test on IMDB\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a writer to write to Tensorboard\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # Create classifier model\n",
    "    model = Transformer(k, heads=heads, num_layers=num_layers,\n",
    "                        input_length=MAX_LENGTH, num_inputs=VOCAB_SIZE,\n",
    "                        num_outputs=NUM_CLASSES, dropout=dropout)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # Create loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "    lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda i: min(i / (10_000 / BATCH_SIZE), 1.0))\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f'\\n Epoch {epoch}')\n",
    "        \n",
    "        # Train on data\n",
    "        train_loss, train_acc = train(train_iter,\n",
    "                                      model,\n",
    "                                      optimizer,\n",
    "                                      lr_scheduler,\n",
    "                                      criterion)\n",
    "\n",
    "        # Test on data\n",
    "        test_loss, test_acc = test(test_iter,\n",
    "                                   model,\n",
    "                                   criterion)\n",
    "\n",
    "        # Write metrics to Tensorboard\n",
    "        writer.add_scalars('Loss', {\n",
    "            'Train': train_loss,\n",
    "            'Test': test_loss\n",
    "        }, epoch)\n",
    "        writer.add_scalars('Accuracy', {\n",
    "            'Train': train_acc,\n",
    "            'Test': test_acc\n",
    "        }, epoch)\n",
    "        writer.flush()\n",
    "\n",
    "    print('\\nFinished.')\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5gMFb7Hhfv3"
   },
   "source": [
    "Train the model. Try different configurations: how do the various hyperparameters affect the model's performance?\n",
    "\n",
    "**WARNING:** Training can take fairly long (i.e. a couple of minutes per epoch) for larger models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_y1XFHrhSBJB"
   },
   "outputs": [],
   "source": [
    "run(epochs=5, k=64, heads=4, num_layers=4, dropout=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa7ezcrgg0FU"
   },
   "source": [
    "Again, we will inspect the results in tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XiZ-6Eg_5Mqt"
   },
   "outputs": [],
   "source": [
    "# Open Tensorboard (for Google Colab users)\n",
    "%tensorboard --logdir runs/\n",
    "\n",
    "# For local users only: uncomment the last line, run this cell once and wait for\n",
    "# it to time out, run this cell a second time and you should see the board.\n",
    "# %tensorboard --logdir runs/ --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vdbCkpYheZa"
   },
   "outputs": [],
   "source": [
    "# To completely clean your tensorboard uncomment and run the following command.\n",
    "# !rm -r runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS5kdIqqGqC4"
   },
   "source": [
    "This concludes assignment 7!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_7.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
